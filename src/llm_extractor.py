import base64
import instructor
from openai import OpenAI
from .models import Factura
from .ingestor import Document

# -----------------------------------------------------------------------------
# 3. MOTOR DE EXTRACCI칍N (LLM + Instructor)
# -----------------------------------------------------------------------------
# 쯈U칄 ES ESTO?
# Es el cerebro. Toma una imagen y devuelve un objeto Python validado.
# Usa la librer칤a 'instructor' para parchear el cliente de OpenAI.
#
# 쯇OR QU칄 AS칈 EN PRODUCCI칍N?
# 1. Salida Estructurada Garantizada: No le pedimos "dame un JSON", le pedimos
#    "rellena esta clase Pydantic". Si el LLM falla, 'instructor' reintenta
#    autom치ticamente pas치ndole el error de validaci칩n al LLM para que se corrija.
# 2. Visi칩n Multimodal: Usamos GPT-4o porque "ve" la factura como un humano.
#    OCR tradicional (Tesseract) falla mucho con tablas y formatos raros.
# 3. Reintentos (Retries): En producci칩n, las APIs fallan. Instructor maneja
#    autom치ticamente los reintentos si la validaci칩n de Pydantic falla.
# -----------------------------------------------------------------------------

def encode_image(image_path: str) -> str:
    """Codifica una imagen a base64 para enviarla a GPT-4o."""
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode('utf-8')

class LLMExtractor:
    def __init__(self, api_key: str):
        # Inicializamos el cliente "parcheado" por instructor
        self.client = instructor.from_openai(OpenAI(api_key=api_key))
        # Modelo a usar. GPT-4o es ideal para visi칩n + texto.
        self.model_name = "gpt-4o" 

    def extract(self, document: Document) -> Factura:
        """
        Toma un documento (PDF o Imagen) y extrae los datos en estructura Factura.
        Nota: Para este MVP, asumimos que si es PDF, GPT-4o puede leerlo si se convierte a imagen
        o si usamos un parser de texto antes. 
        Para simplificar el MVP, trataremos todo como "visi칩n" (ideal para im치genes) 
        o texto crudo si pudi칠ramos extraerlo.
        
        *TRUCO*: GPT-4o funciona muy bien con im치genes. Si el PDF es de una p치gina,
        lo ideal es convertirlo a imagen. Si es texto seleccionable, mejor pasar el texto.
        Aqu칤, para simplificar, asumiremos que el usuario nos da im치genes o PDFs que 
        podemos tratar (en un MVP real usar칤amos 'pdf2image' para convertir PDFs).
        """
        
        print(f"游 Analizando documento: {document.filename}...")

        # Construimos el mensaje para el LLM
        # Si es una imagen (jpg, png), la enviamos como payload de visi칩n.
        # Si fuera un PDF complejo, habr칤a que extraer texto o convertir a imagen.
        # Aqu칤 haremos una implementaci칩n b치sica que asume que si es imagen, enviamos imagen.
        
        extension = document.filename.split('.')[-1].lower()
        messages = []

        if extension in ['jpg', 'jpeg', 'png', 'webp']:
            # Flujo de Visi칩n
            base64_image = encode_image(document.filepath)
            messages = [
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": "Extrae la informaci칩n de esta factura. Si alg칰n campo no est치 claro, d칠jalo vac칤o o infi칠relo con sentido com칰n."},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{base64_image}"
                            },
                        },
                    ],
                }
            ]
        else:
            # Flujo de Texto (asumiendo PDF de texto o fallback)
            # En un caso real: usar칤amos pypdf para extraer texto.
            # Para este MVP educativo: Le decimos al usuario que use im치genes o 
            # implementamos un extractor de texto simple si fuera necesario.
            # Por ahora, simularemos que leemos el archivo como texto si no es imagen,
            # (esto fallar치 con PDFs binarios, pero sirve para explicar el concepto).
            messages = [
                {
                    "role": "user", 
                    "content": f"Extrae los datos de esta factura (nombre archivo: {document.filename}). [Aqu칤 ir칤a el contenido OCR o texto extra칤do]"
                }
            ]
            print("丘멆잺 AVISO: Este MVP b치sico est치 optimizado para im치genes (JPG/PNG). Para PDFs reales, necesitar칤amos 'pdf2image' o 'pypdf'.")

        # Llamada m치gica a Instructor
        factura_extraida = self.client.chat.completions.create(
            model=self.model_name,
            response_model=Factura, # <--- AQU칈 EST츼 LA CLAVE
            messages=messages,
            temperature=0.0, # Determinista
        )
        
        return factura_extraida
